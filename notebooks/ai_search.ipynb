{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk\n",
    "%pip install openai\n",
    "%pip install pdfminer.six\n",
    "%pip install text_chunker\n",
    "%pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from pdfminer.high_level import extract_text\n",
    "from openai import AzureOpenAI\n",
    "from text_chunker import TextChunker\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "\n",
    "TEXT_EMBEDDING_ADA_002 = \"text-embedding-ada-002\"\n",
    "chunck_size = 8191\n",
    "index_name = \"faq-bc-arquivo\"\n",
    "\n",
    "chukner = TextChunker(maxlen=chunck_size)\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "\n",
    "# inicialização do cliente Azure OpenAI\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return extract_text(file_path)\n",
    "    else:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "        return text\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    start_time = time.perf_counter()\n",
    "    embeddings = client.embeddings.create(input = [text], model=TEXT_EMBEDDING_ADA_002).data[0].embedding\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    return embeddings, elapsed_time\n",
    "\n",
    "def upload_document(document):\n",
    "    result = search_client.upload_documents(documents=[document])\n",
    "    print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n",
    "\n",
    "def merge_document():\n",
    "    result = search_client.merge_documents(documents=[{\"hotelId\": \"1000\", \"rating\": 4.5}])\n",
    "    print(\"Merge into new document succeeded: {}\".format(result[0].succeeded))\n",
    "\n",
    "\n",
    "def delete_document():\n",
    "    result = search_client.delete_documents(documents=[{\"hotelId\": \"1000\"}])\n",
    "    print(\"Delete new document succeeded: {}\".format(result[0].succeeded))\n",
    "\n",
    "def get_document(id):\n",
    "    result = search_client.get_document(id)\n",
    "\n",
    "    print(\"Details:\")\n",
    "    print(\"Filepath: {}\".format(result[\"filepath\"]))\n",
    "    print(\"Title: {}\".format(result[\"title\"]))\n",
    "    print(\"URL: {}\".format(result[\"url\"]))\n",
    "    print(\"Content: {}\".format(result[\"content\"]))\n",
    "    print(\"ContentVector: {}\".format(result[\"contentVector\"]))\n",
    "\n",
    "def query(query_string):\n",
    "    results = search_client.search(search_text=query_string, top=5)\n",
    "    print(\"Search results:\")\n",
    "    for result in results:\n",
    "        print(\"Filepath: {}\".format(result[\"filepath\"]))\n",
    "        print(\"Title: {}\".format(result[\"title\"]))\n",
    "        print(\"URL: {}\".format(result[\"url\"]))\n",
    "        print(\"Content: {}\".format(result[\"content\"]))\n",
    "        print(\"ContentVector: {}\".format(result[\"contentVector\"]))\n",
    "        print(\"====================================\")\n",
    "\n",
    "# funcao para dividir o texto em chunks\n",
    "def chunk_text(text):\n",
    "    chunks = chukner.chunk(text)\n",
    "    return chunks\n",
    "\n",
    "# funcao para ler um arquivo e dividir em chunks\n",
    "def chunk_file(file_path):\n",
    "    text = read_file(file_path)\n",
    "    chunks = chunk_text(text)\n",
    "    return chunks\n",
    "\n",
    "# funcao para gerar embeddings de um arquivo\n",
    "def generate_embeddings_file(file_path, model):\n",
    "    chunks = chunk_file(file_path)\n",
    "    embeddings = []\n",
    "    elapsed_time = 0\n",
    "    for chunk in chunks:\n",
    "        chunk_embeddings, chunk_elapsed_time = generate_embeddings(chunk, model)\n",
    "        embeddings.append(chunk_embeddings)\n",
    "        elapsed_time += chunk_elapsed_time\n",
    "    return embeddings, elapsed_time\n",
    "\n",
    "# funcao para gerar um uuid para o arquivo\n",
    "def generate_uuid():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "def index_file(file_path):\n",
    "    title = os.path.basename(file_path)\n",
    "    chunks = chunk_file(file_path)\n",
    "    last_updated = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime(os.path.getmtime(file_path)))\n",
    "    chunk_id = 0\n",
    "    for chunk in chunks:\n",
    "        chunk_id += 1\n",
    "        embeddings, elapsed_time = generate_embeddings(chunk)\n",
    "        document = {\n",
    "            \"content\": chunk,\n",
    "            \"filepath\": file_path,\n",
    "            \"title\": title,\n",
    "            \"url\": \"file://\" + file_path,\n",
    "            \"id\": generate_uuid(),\n",
    "            \"chunk_id\": f\"{chunk_id}\",\n",
    "            \"last_updated\": last_updated,\n",
    "            \"contentVector\": embeddings\n",
    "        }\n",
    "        upload_document(document)\n",
    "        print(document)\n",
    "    print(f\"File indexed successfully! Total chunks: {chunk_id} - Elapsed time: {elapsed_time} seconds\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def index_directory(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                index_file(file_path)\n",
    "    return True\n",
    "\n",
    "#arquivo = \"/Users/rodam/Downloads/Manual beneficios.pdf\"\n",
    "#index_file(arquivo)\n",
    "query_string = \"manual de beneficios\"\n",
    "query(query_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
