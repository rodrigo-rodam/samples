{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade eyed3\n",
    "%pip install --upgrade openai\n",
    "%pip install --upgrade python-dotenv\n",
    "%pip install --upgrade pydub\n",
    "%pip install --upgrade soundfile\n",
    "%pip install --upgrade openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# inicialização do cliente Whisper\n",
    "openai = AzureOpenAI(api_key=os.getenv(\"AZURE_OPENAI_KEY_NORTHCENTRALUS\"),\n",
    "                      azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT_NORTHCENTRALUS\"), \n",
    "                      api_version=os.getenv(\"WHISPER_VERSION\"))\n",
    "\n",
    "# Verifica se o arquivo de áudio precisa ser dividido\n",
    "def need_to_split(file_path, size_threshold_mb=25, duration_threshold_minutes=3):\n",
    "    print(f\"Checking if {file_path} needs to be split\")\n",
    "    size_threshold_bytes = size_threshold_mb * 1024 * 1024\n",
    "    duration_threshold_ms = duration_threshold_minutes * 60 * 1000\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    file_size = os.path.getsize(file_path)\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio_duration = len(audio)\n",
    "    \n",
    "    if file_size > size_threshold_bytes or audio_duration > duration_threshold_ms:\n",
    "        print(f\"The file {file_path} needs to be split.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"The file {file_path} does not need to be split.\")\n",
    "        return False\n",
    "\n",
    "# conversão do áudio para mp3\n",
    "def compress_audio(file_path, ext=\"mp3\"):\n",
    "    print(f\"Compressing {file_path} to {ext}\")\n",
    "    file_root, _ = os.path.splitext(file_path)\n",
    "    file_compressed = f\"{file_root}.{ext}\"\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(file_path, codec=\"adpcm_ima_wav\")\n",
    "    audio.export(file_compressed, format=ext, parameters=[\"-ac\",\"2\",\"-ar\",\"8000\"])\n",
    "    return file_compressed\n",
    "\n",
    "# Faz o split do arquivo de áudio em arquivos menores\n",
    "def split_audio(file_path, chunk_size_kb=None, chunk_duration_minutes=None):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    \n",
    "    if chunk_size_kb:\n",
    "        file_size_kb = os.path.getsize(file_path) / 1024\n",
    "        num_chunks = int(file_size_kb // chunk_size_kb) + 1\n",
    "        chunk_duration_ms = len(audio) / num_chunks\n",
    "    elif chunk_duration_minutes:\n",
    "        chunk_duration_ms = chunk_duration_minutes * 60 * 1000\n",
    "        num_chunks = int(len(audio) // chunk_duration_ms) + 1\n",
    "    else:\n",
    "        raise ValueError(\"Either chunk_size_kb or chunk_duration_minutes must be provided.\")\n",
    "    \n",
    "    chunks = [audio[i * chunk_duration_ms:(i + 1) * chunk_duration_ms] for i in range(num_chunks)]\n",
    "    \n",
    "    base_name, ext = os.path.splitext(file_path)\n",
    "    chunk_files = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file = f\"{base_name}_chunk{i + 1}{ext}\"\n",
    "        chunk.export(chunk_file, format=ext[1:])\n",
    "        chunk_files.append(chunk_file)\n",
    "    \n",
    "    return chunk_files\n",
    "    \n",
    "\n",
    "def transcript_audio_to_text_splitting(audio_file_path, model=\"whisper\", region=\"northcentralus\"):\n",
    "    print(f\"Transcribing {audio_file_path} with model {model}\")\n",
    "    start_time = time.perf_counter()\n",
    "    split_files = split_audio(audio_file_path, chunk_size_kb=None, chunk_duration_minutes=5)\n",
    "    print(f\"Split audio into {len(split_files)} chunks\")\n",
    "    transcriptions = []\n",
    "    for audio_file in split_files:\n",
    "        transcriptions.append(transcript_audio_to_text(audio_file, model, region))\n",
    "    \n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    return {\"0.elapsed_time\": elapsed_time,\"1.transcriptions\": transcriptions}\n",
    "\n",
    "\n",
    "def transcript_audio_to_text(audio_file_path, model=\"whisper\", region=\"northcentralus\"):\n",
    "    print(f\"Transcribing {audio_file_path} with model {model}\")\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        transcription = openai.audio.transcriptions.create(\n",
    "            model=model,\n",
    "            file=audio_file\n",
    "    )\n",
    "    file_root, _ = os.path.splitext(audio_file_path)\n",
    "    transcript_file = f\"{file_root}.txt\"\n",
    "    append_to_file(transcript_file, transcription.text)\n",
    "    return transcription\n",
    "\n",
    "def append_to_file(file_path, content):\n",
    "\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(content)\n",
    "        file.write('\\n')  # Optionally add a newline after the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if C:/Users/rmendonca/Downloads/teste.mp3 needs to be split\n",
      "The file C:/Users/rmendonca/Downloads/teste.mp3 does not need to be split.\n",
      "Transcribing C:/Users/rmendonca/Downloads/teste.mp3 with model whisper\n",
      "Transcription: Esse áudio eu vou usar para testar a capacidade de transcription do GPT-4O ou talvez outros modelos de transcription dentro do Fabric. Para isso eu vou ler um trecho da Wikipedia. Escolhi aqui o trecho que trata da vida de Ana Nery. Ana Justina Ferreira Nery, mais conhecida como Ana Nery. Nascida em 13 de dezembro de 1814, na cidade de Cachoeira. Veio a falecer no dia 20 de maio de 1880, no Rio de Janeiro. Foi uma enfermeira brasileira, pioneira da enfermagem no Brasil. É conhecida como a mãe dos brasileiros. Apelido compartilhado entre outros. Biografia. Antes da guerra do Paraguai. Filha de José Ferreira de Jesus e Luísa Maria das Virgens. Ana Justina Ferreira. Nasceu em Cachoeira da Bahia. Casou-se com o capitão de fragata Isidoro Antônio Nery em 1837. Quando adotou o sobrenome do marido, que viria a consagrá-la como Ana Nery. Com o cônjuge teve três filhos. Justiniano Nery, Antônio Pedro Nery e Isidoro Antônio Nery Filho. O marido morreu em 1843.\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"C:/Users/rmendonca/Downloads/teste.mp3\"\n",
    "\n",
    "if need_to_split(audio_file):\n",
    "    transcript = transcript_audio_to_text_splitting(audio_file)\n",
    "else:\n",
    "    transcript = transcript_audio_to_text(audio_file)\n",
    "\n",
    "print(\"Transcription:\", transcript.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
