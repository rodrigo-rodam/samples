{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade eyed3\n",
    "%pip install --upgrade openai\n",
    "%pip install --upgrade python-dotenv\n",
    "%pip install --upgrade pydub\n",
    "%pip install --upgrade soundfile\n",
    "%pip install --upgrade openai-whisper\n",
    "%pip install --upgrade azure-cognitiveservices-speech\n",
    "%pip install --upgrade playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7044 sha256=1e4ad59c8d2b881546b6a3e95a35f6ba765e5102f1fca2042307e3746a923798\n",
      "  Stored in directory: c:\\users\\rmendonca\\appdata\\local\\pip\\cache\\wheels\\50\\98\\42\\62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from playsound import playsound\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inicialização do cliente Whisper\n",
    "openai = AzureOpenAI(api_key=os.getenv(\"AZURE_OPENAI_KEY_NORTHCENTRALUS\"),\n",
    "                      azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT_NORTHCENTRALUS\"), \n",
    "                      api_version=os.getenv(\"WHISPER_VERSION\"))\n",
    "\n",
    "# Verifica se o arquivo de áudio precisa ser dividido\n",
    "def need_to_split(file_path, size_threshold_mb=25, duration_threshold_minutes=3):\n",
    "    print(f\"Checking if {file_path} needs to be split\")\n",
    "    size_threshold_bytes = size_threshold_mb * 1024 * 1024\n",
    "    duration_threshold_ms = duration_threshold_minutes * 60 * 1000\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    file_size = os.path.getsize(file_path)\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio_duration = len(audio)\n",
    "    \n",
    "    if file_size > size_threshold_bytes or audio_duration > duration_threshold_ms:\n",
    "        print(f\"The file {file_path} needs to be split.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"The file {file_path} does not need to be split.\")\n",
    "        return False\n",
    "\n",
    "# conversão do áudio para mp3\n",
    "def compress_audio(file_path, ext=\"mp3\"):\n",
    "    print(f\"Compressing {file_path} to {ext}\")\n",
    "    file_root, _ = os.path.splitext(file_path)\n",
    "    file_compressed = f\"{file_root}.{ext}\"\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(file_path, codec=\"adpcm_ima_wav\")\n",
    "    audio.export(file_compressed, format=ext, parameters=[\"-ac\",\"2\",\"-ar\",\"8000\"])\n",
    "    return file_compressed\n",
    "\n",
    "# Faz o split do arquivo de áudio em arquivos menores\n",
    "def split_audio(file_path, chunk_size_kb=None, chunk_duration_minutes=None):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    \n",
    "    if chunk_size_kb:\n",
    "        file_size_kb = os.path.getsize(file_path) / 1024\n",
    "        num_chunks = int(file_size_kb // chunk_size_kb) + 1\n",
    "        chunk_duration_ms = len(audio) / num_chunks\n",
    "    elif chunk_duration_minutes:\n",
    "        chunk_duration_ms = chunk_duration_minutes * 60 * 1000\n",
    "        num_chunks = int(len(audio) // chunk_duration_ms) + 1\n",
    "    else:\n",
    "        raise ValueError(\"Either chunk_size_kb or chunk_duration_minutes must be provided.\")\n",
    "    \n",
    "    chunks = [audio[i * chunk_duration_ms:(i + 1) * chunk_duration_ms] for i in range(num_chunks)]\n",
    "    \n",
    "    base_name, ext = os.path.splitext(file_path)\n",
    "    chunk_files = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file = f\"{base_name}_chunk{i + 1}{ext}\"\n",
    "        chunk.export(chunk_file, format=ext[1:])\n",
    "        chunk_files.append(chunk_file)\n",
    "    \n",
    "    return chunk_files\n",
    "    \n",
    "\n",
    "def transcript_audio_to_text_splitting(audio_file_path, model=\"whisper\", region=\"northcentralus\"):\n",
    "    print(f\"Transcribing {audio_file_path} with model {model}\")\n",
    "    start_time = time.perf_counter()\n",
    "    split_files = split_audio(audio_file_path, chunk_size_kb=None, chunk_duration_minutes=5)\n",
    "    print(f\"Split audio into {len(split_files)} chunks\")\n",
    "    transcriptions = []\n",
    "    for audio_file in split_files:\n",
    "        transcriptions.append(transcript_audio_to_text(audio_file, model, region))\n",
    "    \n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    return {\"0.elapsed_time\": elapsed_time,\"1.transcriptions\": transcriptions}\n",
    "\n",
    "\n",
    "def transcript_audio_to_text(audio_file_path, model=\"whisper\", region=\"northcentralus\"):\n",
    "    print(f\"Transcribing {audio_file_path} with model {model}\")\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        transcription = openai.audio.transcriptions.create(\n",
    "            model=model,\n",
    "            file=audio_file\n",
    "    )\n",
    "    file_root, _ = os.path.splitext(audio_file_path)\n",
    "    transcript_file = f\"{file_root}.txt\"\n",
    "    append_to_file(transcript_file, transcription.text)\n",
    "    return transcription\n",
    "\n",
    "def append_to_file(file_path, content):\n",
    "\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(content)\n",
    "        file.write('\\n')  # Optionally add a newline after the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if C:/Users/rmendonca/Downloads/teste.mp3 needs to be split\n",
      "The file C:/Users/rmendonca/Downloads/teste.mp3 does not need to be split.\n",
      "Transcribing C:/Users/rmendonca/Downloads/teste.mp3 with model whisper\n",
      "Transcription: Esse áudio eu vou usar para testar a capacidade de transcription do GPT-4O ou talvez outros modelos de transcription dentro do Fabric. Para isso eu vou ler um trecho da Wikipedia. Escolhi aqui o trecho que trata da vida de Ana Nery. Ana Justina Ferreira Nery, mais conhecida como Ana Nery. Nascida em 13 de dezembro de 1814, na cidade de Cachoeira. Veio a falecer no dia 20 de maio de 1880, no Rio de Janeiro. Foi uma enfermeira brasileira, pioneira da enfermagem no Brasil. É conhecida como a mãe dos brasileiros. Apelido compartilhado entre outros. Biografia. Antes da guerra do Paraguai. Filha de José Ferreira de Jesus e Luísa Maria das Virgens. Ana Justina Ferreira. Nasceu em Cachoeira da Bahia. Casou-se com o capitão de fragata Isidoro Antônio Nery em 1837. Quando adotou o sobrenome do marido, que viria a consagrá-la como Ana Nery. Com o cônjuge teve três filhos. Justiniano Nery, Antônio Pedro Nery e Isidoro Antônio Nery Filho. O marido morreu em 1843.\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"C:/Users/rmendonca/Downloads/teste.mp3\"\n",
    "\n",
    "if need_to_split(audio_file):\n",
    "    transcript = transcript_audio_to_text_splitting(audio_file)\n",
    "else:\n",
    "    transcript = transcript_audio_to_text(audio_file)\n",
    "\n",
    "print(\"Transcription:\", transcript.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom voice name: Rodam_v1\n",
      "Custom endpoint id: 39b3f6c9-41b6-43a2-bd1d-13445e77c06b\n",
      "Speech synthesized for text [Oi, esta é a minha voz personalizada.], and the audio was saved to [sample.wav]\n"
     ]
    }
   ],
   "source": [
    "#custom model\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Creates an instance of a speech config with specified subscription key and service region.\n",
    "speech_key = os.getenv(\"CUSTOM_SPEECH_KEY\")\n",
    "service_region = \"eastus\"\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "speech_config.endpoint_id = os.getenv(\"CUSTOM_SPEECH_ENDPOINT_ID\")\n",
    "speech_config.speech_synthesis_voice_name = os.getenv(\"SPEECH_SYNTESIS_VOICE_NAME\")\n",
    "speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3)\n",
    "print(\"Custom voice name:\", speech_config.speech_synthesis_voice_name)\n",
    "print(\"Custom endpoint id:\", speech_config.endpoint_id)\n",
    "text = \"Oi, esta é a minha voz personalizada.\"\n",
    "file_name = \"sample.wav\"\n",
    "\n",
    "# using the default speaker as audio output.\n",
    "file_config = speechsdk.audio.AudioOutputConfig(filename=file_name)\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)\n",
    "\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "# Check result\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}], and the audio was saved to [{}]\".format(text, file_name))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open sample.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close sample.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: sample.wav\n"
     ]
    },
    {
     "ename": "PlaysoundException",
     "evalue": "\n    Error 263 for command:\n        open sample.wav\n    The specified device is not open or is not recognized by MCI.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPlaysoundException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplaysound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rmendonca\\codes\\.venv\\Lib\\site-packages\\playsound.py:72\u001b[0m, in \u001b[0;36m_playsoundWin\u001b[1;34m(sound, block)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m     \u001b[43mwinCommand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msound\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     winCommand(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sound, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m wait\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     74\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rmendonca\\codes\\.venv\\Lib\\site-packages\\playsound.py:64\u001b[0m, in \u001b[0;36m_playsoundWin.<locals>.winCommand\u001b[1;34m(*command)\u001b[0m\n\u001b[0;32m     60\u001b[0m     exceptionMessage \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    Error \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(errorCode) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for command:\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     61\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m command\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     62\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m errorBuffer\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     63\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(exceptionMessage)\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PlaysoundException(exceptionMessage)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[1;31mPlaysoundException\u001b[0m: \n    Error 263 for command:\n        open sample.wav\n    The specified device is not open or is not recognized by MCI."
     ]
    }
   ],
   "source": [
    "playsound(\"sample.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
