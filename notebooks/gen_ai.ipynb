{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# install libraries\n",
    "%pip install --upgrade tiktoken\n",
    "%pip install --upgrade openai\n",
    "%pip install --upgrade python-dotenv\n",
    "%pip install --upgrade pydub\n",
    "%pip install --upgrade soundfile\n",
    "%pip install --upgrade openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "import pprint\n",
    "import tiktoken\n",
    "import tempfile\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções que serão utilizadas durante os exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome das regiões Azure OpenAI\n",
    "EASTUS = \"eastus\"\n",
    "CANADAEAST = \"canadaeast\"\n",
    "NORTHCENTRALUS = \"northcentralus\"\n",
    "\n",
    "# Nome dos modelos Azure OpenAI criados na subscrição \n",
    "GPT_35_TURBO = \"gpt-35-turbo\"\n",
    "GPT_35_TURBO_16K = \"gpt-35-turbo-16k\"\n",
    "GPT_35_TURBO_INSTRUCT = \"gpt-35-turbo-instruct\"\n",
    "\n",
    "GPT_4 = \"gpt-4\"\n",
    "GPT_4_32K = \"gpt-4-32k\"\n",
    "GPT_4_TURBO = \"gpt-4-turbo\"\n",
    "GPT_4o = \"gpt-4o\"\n",
    "GPT_4o_mini = \"gpt-4o-mini\"\n",
    "\n",
    "DALL_E_3 = \"dall-e-3\"\n",
    "WHISPER = \"whisper\"\n",
    "TEXT_EMBEDDING_ADA_002 = \"text-embedding-ada-002\"\n",
    "TEXT_EMBEDDING_ADA_3_SMALL = \"text-embedding-3-small\"\n",
    "TEXT_EMBEDDING_ADA_3_LARGE = \"text-embedding-3-large\"\n",
    "\n",
    "# Whisper limit 25MB files\n",
    "audio_chunk_size_kb = 1024 * 22\n",
    "\n",
    "\n",
    "load_dotenv() # carregar variáveis de ambiente\n",
    "\n",
    "# gpt-4o em northcentralus 2024-05-13\n",
    "# gpt-4o em eastus 2024-08-06\n",
    "\n",
    "deployments_in_regions = {\"CANADAEAST\": [GPT_35_TURBO, GPT_4, GPT_4_32K, GPT_4_TURBO, TEXT_EMBEDDING_ADA_002, TEXT_EMBEDDING_ADA_3_SMALL],\n",
    "                          \"EASTUS\": [GPT_35_TURBO_16K, GPT_35_TURBO_INSTRUCT, GPT_4o, GPT_4o_mini, DALL_E_3, TEXT_EMBEDDING_ADA_002, TEXT_EMBEDDING_ADA_3_LARGE],\n",
    "                          \"NORTHCENTRALUS\": [WHISPER, GPT_4o]}\n",
    "\n",
    "\n",
    "# carregar tokenizador para os modelos de linguagem\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# inicialização do cliente Azure OpenAI Canada East\n",
    "client_canadaeast = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_CANADAEAST\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY_CANADAEAST\"),  \n",
    "    api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "# inicialização do cliente Azure OpenAI East US\n",
    "client_eastus = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_EASTUS\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY_EASTUS\"),  \n",
    "    api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "# inicialização do cliente Azure OpenAI North Central US\n",
    "client_northcentralus = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_NORTHCENTRALUS\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY_NORTHCENTRALUS\"),  \n",
    "    api_version=os.getenv(\"WHISPER_VERSION\")\n",
    ")\n",
    "\n",
    "\n",
    "# funcao para retornar o cliente de acordo com a região\n",
    "def get_client(region):\n",
    "    if region == \"canadaeast\":\n",
    "        return client_canadaeast\n",
    "    elif region == \"eastus\":\n",
    "        return client_eastus\n",
    "    elif region == \"northcentralus\":\n",
    "        return client_northcentralus\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# função para chamar o modelo de linguagem\n",
    "def call_llm(deployment_name, system_message, prompt, file_path, region=\"canadaeast\"):\n",
    "\n",
    "    if deployment_name not in deployments_in_regions[region.upper()]:\n",
    "        return {\"0.error\": f\"Model {deployment_name} not available in region {region}\", \n",
    "                \"1.This regions has the following models available\": deployments_in_regions[region.upper()], \n",
    "                f\"2.The model {deployment_name} is available in the following regions\": [region for region, models in deployments_in_regions.items() if deployment_name in models]}\n",
    "    \n",
    "    client = get_client(region)\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_message},{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    if file_path:\n",
    "        print(\"file_path\", file_path)\n",
    "        messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}, get_content_file(file_path)]}]\n",
    "    \n",
    "    print(\"messages\", messages)\n",
    "    response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = messages\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time # usado para calcular o tempo de execução\n",
    "    resp = response.choices[0].message.content\n",
    "    tokens_completion = num_tokens_from_string(resp, deployment_name) # conta os tokens da resposta\n",
    "    # conta os tokens da mensagem do sistema e da pergunta (prompt)\n",
    "    tokens_prompt = num_tokens_from_string(system_message, deployment_name) + num_tokens_from_string(prompt, deployment_name)\n",
    "    # formatar a resposta da função\n",
    "    return {\"0.model\": deployment_name, \n",
    "            \"1.elapsed_time\": elapsed_time, \n",
    "            \"2.response\": resp, \n",
    "            \"3.num_tokens_completion\": tokens_completion, \n",
    "            \"4.num_tokens_prompt\": tokens_prompt,\n",
    "            \"5.system_message\": system_message,\n",
    "            \"6.prompt\": prompt}\n",
    "\n",
    "def get_content_file(file_path):\n",
    "    response = {}\n",
    "    if file_path.endswith(\".wav\"):\n",
    "        with open(file_path, \"rb\") as audio_file:\n",
    "            response = {\n",
    "              \"type\": \"audio_url\",\n",
    "              \"audio_url\": {\n",
    "                \"url\": f\"data:audio/wav;base64,{base64.b64encode(audio_file.read()).decode()}\",\n",
    "                \"detail\": \"auto\"\n",
    "              }\n",
    "            }\n",
    "    elif file_path.endswith(\".jpg\") or file_path.endswith(\".jpeg\") or file_path.endswith(\".png\"):\n",
    "        with open(file_path, \"rb\") as image_file:\n",
    "            response = {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\":  f\"data:image/jpeg;base64,{base64.b64encode(image_file.read()).decode('utf-8')}\",\n",
    "                        \"detail\": \"auto\"\n",
    "                    }\n",
    "                }\n",
    "    elif file_path.endswith(\".pdf\"):\n",
    "        with open(file_path, \"rb\") as pdf_file:\n",
    "            response = {\n",
    "                \"type\": \"text\",\n",
    "                \"file\": {\n",
    "                    \"url\": f\"data:text/pdf;base64,{base64.b64encode(pdf_file.read()).decode()}\",\n",
    "                    \"detail\": \"auto\"\n",
    "                }\n",
    "            }\n",
    "    else:\n",
    "        response = {\n",
    "            \"type\": \"file\",\n",
    "            \"file\": {\n",
    "                \"url\": f\"data:file/octet-stream;base64,{base64.b64encode(open(file_path, 'rb').read()).decode()}\",\n",
    "                \"detail\": \"auto\"\n",
    "            }\n",
    "        }\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "# funcao para contar tokens\n",
    "def num_tokens_from_string(texto, model):\n",
    "    if not texto:\n",
    "        return 0\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(texto))\n",
    "    return num_tokens\n",
    "\n",
    "# função para gerar embeddings\n",
    "def generate_embeddings(text, model, region=\"canadaeast\"):\n",
    "    client = get_client(region)\n",
    "    start_time = time.perf_counter()\n",
    "    embeddings = client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    return embeddings, elapsed_time\n",
    "\n",
    "# função para executar modelos simultaneamente\n",
    "# models: lista de modelos\n",
    "# system_message: mensagem do sistema\n",
    "# prompt: pergunta\n",
    "# retorna uma lista com os resultados\n",
    "def execute_simultaneously(models, system_message, prompt, debug=False, region=\"canadaeast\"):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(call_llm, model, system_message, prompt, None, region) for model in models]\n",
    "        results = []\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            if debug:\n",
    "                print_result(future.result(), debug)\n",
    "            results.append(future.result())\n",
    "    return results\n",
    "\n",
    "def print_result(result, debug=False):\n",
    "    print(\"Elapsed time:\", result[\"1.elapsed_time\"])\n",
    "    print(\"Response:\", result[\"2.response\"])\n",
    "    print(\"Num tokens completion:\", result[\"3.num_tokens_completion\"])\n",
    "    print(\"Num tokens prompt:\", result[\"4.num_tokens_prompt\"])\n",
    "    if debug:\n",
    "        print(\"System message:\", result[\"5.system_message\"])\n",
    "        print(\"Prompt:\", result[\"6.prompt\"])\n",
    "        print(\"Model:\", result[\"0.model\"])\n",
    "        print(\"===========================================================\\n\")  \n",
    "\n",
    "#funcao para imprimir resultados\n",
    "def print_results(system_message, prompt, results, debug=False):\n",
    "    if debug:\n",
    "        print(\"System message:\", system_message)\n",
    "        print(\"Prompt:\", prompt)\n",
    "\n",
    "    for result in results:\n",
    "        print(\"Model:\", result[\"0.model\"], \"Elapsed time:\", result[\"1.elapsed_time\"])\n",
    "        print(\"Response:\", result[\"2.response\"])\n",
    "        print(\"Num tokens completion:\", result[\"3.num_tokens_completion\"], \n",
    "              \", Num tokens prompt:\", result[\"4.num_tokens_prompt\"])\n",
    "        print(\"===========================================================\\n\")\n",
    "\n",
    "# funcao para criar arquivo temporario\n",
    "def create_temp_file(content, file_extension):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:\n",
    "        temp_file.write(content.encode())\n",
    "        temp_file_path = temp_file.name\n",
    "    return temp_file_path\n",
    "\n",
    "# funcao para executar arquivo python externo\n",
    "def execute_external_script(script_path, *args):\n",
    "    command = [\"python\", script_path] + list(args)\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    return result.stdout, result.stderr, result.returncode\n",
    "\n",
    "# funcao para executar arquivo python temporario\n",
    "def execute_temp_script(script_content, *args):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".py\") as temp_script:\n",
    "        temp_script.write(script_content.encode())\n",
    "        temp_script_path = temp_script.name\n",
    "\n",
    "    command = [\"python\", temp_script_path] + list(args)\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Remover o arquivo temporário após a execução\n",
    "    os.remove(temp_script_path)\n",
    "\n",
    "    return result.stdout, result.stderr, result.returncode\n",
    "\n",
    "# executa uma função python que está em uma string\n",
    "def execute_function_from_string(func_code, *args):\n",
    "    func_name = re.search(r\"def (\\w+)\\(\", func_code).group(1)\n",
    "    exec(func_code)\n",
    "    func = locals()[func_name]\n",
    "    return func(*args)\n",
    "\n",
    "# valida se a string contem um json válido se conter retorna o json\n",
    "def hold_llm_json_response(json_string):\n",
    "    # remove o prefixo \"```json\" se existir\n",
    "    json_string = re.sub(r\"^```json\\s*\", \"\", json_string, flags=re.MULTILINE)\n",
    "    # remove o sufixo \"```\" se existir\n",
    "    json_string = re.sub(r\"```$\", \"\", json_string, flags=re.MULTILINE)\n",
    "    if isinstance(json_string, str):\n",
    "        try:\n",
    "            json_string = json.loads(json_string)\n",
    "            return json_string\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Erro ao decodificar o JSON:\", json_string)\n",
    "            json_string = []\n",
    "    else:\n",
    "        print(\"Erro: a resposta não é uma string JSON válida.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Campaign_ID', 'Budget', 'Duration', 'Platform', 'Content_Type',\n",
      "       'Target_Age', 'Target_Gender', 'Region', 'Clicks', 'Conversions', 'CTR',\n",
      "       'CPC', 'Conversion_Rate', 'Success'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_campaign = pd.read_csv(\"../data/ad_campaign_performance.csv\")\n",
    "colunas = df_campaign.columns\n",
    "print(colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [{'role': 'system', 'content': '\\n    Você é um especialista em marketing digital e análise de dados.\\n    Seu trabalho é analisar dados de campanhas de marketing e fornecer insights valiosos.\\n\\n'}, {'role': 'user', 'content': \"\\nPossuo um dataset com as seguintes colunas: \\nIndex(['Campaign_ID', 'Budget', 'Duration', 'Platform', 'Content_Type',\\n       'Target_Age', 'Target_Gender', 'Region', 'Clicks', 'Conversions', 'CTR',\\n       'CPC', 'Conversion_Rate', 'Success'],\\n      dtype='object')\\n\\nQuais insights posso obter a partir deste dataset?\\nGere um json com os seguintes campos:\\n- insights: lista de insights: cada insight deve ser uma string com o insight, uma função python que gera o insight e uma lista de colunas que foram utilizadas para gerar o insight.\\n\\nTodas as funções python devem ser executáveis e devem retornar o insight. Elas devem receber como parâmetro o dataframe e retornar o insight.\\nretorne apenas o json, sem explicações adicionais.\\nNão inclua nenhum outro texto ou explicação.\\n\"}]\n",
      "===========================================================\n",
      "\n",
      "Identificar a campanha com maior taxa de conversão.\n",
      "Resultado: The campaign with the highest conversion rate is: CAMP-X5A5XI\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Determinar a plataforma que gera mais cliques em média.\n",
      "Resultado: The platform with the highest average clicks is: Google\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Analisar a relação entre orçamento e taxa de conversão.\n",
      "Resultado: The correlation between budget and conversion rate is: 0.02\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Comparar a eficiência de custo por clique entre diferentes tipos de conteúdo.\n",
      "Resultado: {'Carousel': 1.6055834985161401, 'Image': 2.611656531672664, 'Story': 4.571864221923045, 'Text': 3.0567252528766757, 'Video': 2.920284824710193}\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Verificar qual região possui maior taxa de conversão.\n",
      "Resultado: The region with the highest conversion rate is: UK\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Avaliando qual faixa etária alvo possui melhor desempenho em conversões.\n",
      "Resultado: The target age group with the best conversion rate is: 55+\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Analisar a diferença de desempenho entre gêneros alvo.\n",
      "Resultado: {'All': 34.008963006893204, 'Female': 22.78145853266124, 'Male': 23.383381544767474}\n",
      "===========================================================\n",
      "\n",
      "===========================================================\n",
      "\n",
      "Avaliar o impacto da duração da campanha na taxa de conversão.\n",
      "Resultado: The correlation between campaign duration and conversion rate is: -0.02\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Possuo um dataset com as seguintes colunas: \n",
    "{colunas}\n",
    "\n",
    "Quais insights posso obter a partir deste dataset?\n",
    "Gere um json com os seguintes campos:\n",
    "- insights: lista de insights: cada insight deve ser uma string com o insight, uma função python que gera o insight e uma lista de colunas que foram utilizadas para gerar o insight.\n",
    "\n",
    "Todas as funções python devem ser executáveis e devem retornar o insight. Elas devem receber como parâmetro o dataframe e retornar o insight.\n",
    "retorne apenas o json, sem explicações adicionais.\n",
    "Não inclua nenhum outro texto ou explicação.\n",
    "'''\n",
    "\n",
    "system_message = '''\n",
    "    Você é um especialista em marketing digital e análise de dados.\n",
    "    Seu trabalho é analisar dados de campanhas de marketing e fornecer insights valiosos.\n",
    "\n",
    "'''\n",
    "\n",
    "r = call_llm(GPT_4o, system_message, prompt, None, EASTUS)\n",
    "\n",
    "insights = r[\"2.response\"]\n",
    "insights = hold_llm_json_response(insights)\n",
    "\n",
    "for insight in insights[\"insights\"]:\n",
    "    insight_code = insight[\"function\"]\n",
    "    print(\"===========================================================\\n\")\n",
    "    print(insight[\"insight\"])\n",
    "    r = execute_function_from_string(insight_code, df_campaign)\n",
    "    print(\"Resultado:\", r)\n",
    "    print(\"===========================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [{'role': 'system', 'content': '\\n    Você é um especialista em Python e pode escrever funções para calcular insights a partir de datasets.\\n'}, {'role': 'user', 'content': \"\\nEscreva uma função em Python para calcular o primeiro insight desta lista de insights: Com esse dataset, você pode analisar uma variedade de aspectos das campanhas de marketing para identificar tendências, comparar eficácia e otimizar futuras estratégias. Aqui estão alguns insights potenciais que você pode obter:\\n\\n1. **Desempenho por Campanha**:\\n   - Compare campanhas com base no sucesso, taxa de conversão (Conversion_Rate) e custo por clique (CPC) para identificar quais foram mais eficazes.\\n\\n2. **Efetividade do Orçamento**:\\n   - Analise a relação entre Budget (orçamento) e Conversions (conversões). Veja se há um ponto de saturação onde aumentar o orçamento não melhora significativamente as conversões.\\n\\n3. **Desempenho por Plataforma**:\\n   - Compare o desempenho (CTR, CPC, taxa de conversão) entre diferentes plataformas para entender onde suas campanhas são mais efetivas.\\n\\n4. **Impacto do Tipo de Conteúdo**:\\n   - Determine como diferentes tipos de conteúdo (Content_Type) influenciam o CTR e a taxa de conversão.\\n\\n5. **Segmentação Demográfica**:\\n   - Analise como diferentes demografias (Target_Age e Target_Gender) respondem às campanhas para identificar o público mais lucrativo.\\n\\n6. **Análise Geográfica**:\\n   - Avalie o desempenho regional para identificar quais áreas são mais receptivas às suas campanhas.\\n\\n7. **Efetividade da Duração**:\\n   - Explore se a duração da campanha tem correlação com o sucesso. Campanhas mais longas ou mais curtas têm mais sucesso?\\n\\n8. **Correlações entre Variáveis**:\\n   - Examine correlações entre variáveis como Budget, Duration e Success para entender quais fatores podem impactar o sucesso da campanha.\\n\\n9. **Análise de Custo**:\\n   - Identifique campanhas com CPC alto e baixo para otimizar o custo por clique, potencialmente redistribuindo orçamento para campanhas mais eficazes.\\n\\n10. **Benchmarking**:\\n    - Compare os resultados das campanhas com benchmarks da indústria para avaliar a competitividade.\\n\\n11. **Análise de Segmentação**:\\n    - Veja quais segmentos (combinação de idade, gênero, região) são mais propensos a converter.\\n\\n12. **Identificação de Anomalias**:\\n    - Use análises estatísticas para identificar anomalias nos dados que podem indicar problemas ou oportunidades não exploradas.\\n\\n13. **Relação entre Clicks e Conversions**:\\n    - Determine se existe uma relação previsível entre o número de cliques e as conversões, o que pode ajudar a prever resultados de campanhas futuras.\\n\\nAo utilizar esses insights, você poderá não apenas avaliar o desempenho passado das campanhas, mas também ajustar estratégias futuras para melhorar a eficácia e otimizar o ROI (retorno sobre investimento).\\npara um dataset com as seguintes colunas: Index(['Campaign_ID', 'Budget', 'Duration', 'Platform', 'Content_Type',\\n       'Target_Age', 'Target_Gender', 'Region', 'Clicks', 'Conversions', 'CTR',\\n       'CPC', 'Conversion_Rate', 'Success'],\\n      dtype='object')\\n\"}]\n",
      "Para calcular o primeiro insight da lista - \"Desempenho por Campanha\" - que envolve a comparação de campanhas com base no sucesso, taxa de conversão (`Conversion_Rate`) e custo por clique (`CPC`), você pode criar uma função em Python que utiliza o Pandas para manipulação de dados e fornece uma análise resumida por campanha. Veja abaixo como essa função pode ser implementada:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "def analyze_campaign_performance(df):\n",
      "    \"\"\"\n",
      "    Analisa o desempenho das campanhas com base em sucesso, taxa de conversão e custo por clique.\n",
      "    \n",
      "    Parâmetros:\n",
      "        df (pd.DataFrame): DataFrame Pandas contendo os dados da campanha.\n",
      "        \n",
      "    Retorna:\n",
      "        pd.DataFrame: Um resumo das campanhas com suas métricas de sucesso.\n",
      "    \"\"\"\n",
      "    # Agrupar dados por 'Campaign_ID' e calcular métricas de interesse\n",
      "    campaign_performance = df.groupby('Campaign_ID').agg({\n",
      "        'Success': 'mean',        # Média de sucesso (presumindo que Success é uma métrica numérica)\n",
      "        'Conversion_Rate': 'mean', # Média da taxa de conversão\n",
      "        'CPC': 'mean'              # Média do custo por clique\n",
      "    }).reset_index()\n",
      "    \n",
      "    # Ordenar o dataframe para uma avaliação mais fácil\n",
      "    campaign_performance_sorted = campaign_performance.sort_values(\n",
      "        by=['Success', 'Conversion_Rate', 'CPC'], \n",
      "        ascending=[False, False, True]  # Para maximizar sucesso e taxa de conversão, mas minimizar CPC\n",
      "    )\n",
      "    \n",
      "    return campaign_performance_sorted\n",
      "\n",
      "# Exemplo de uso:\n",
      "# Assume que 'campaign_data' é um DataFrame Pandas contendo os dados da campanha\n",
      "# campaign_data = pd.read_csv('campaign_data.csv')\n",
      "# print(analyze_campaign_performance(campaign_data))\n",
      "```\n",
      "\n",
      "### Explicação:\n",
      "\n",
      "- **Agrupamento:** A função utiliza `groupby` para agrupar os dados por `Campaign_ID`. Isso permite calcular métricas por campanha, como médias de sucesso, taxa de conversão, e CPC.\n",
      "\n",
      "- **Agregação:** `agg` é usado para calcular a média de cada métrica relevante para cada campanha.\n",
      "\n",
      "- **Ordenação:** Depois de calcular as médias, a função ordena o DataFrame resultante em ordem decrescente de `Success` e `Conversion_Rate` e em ordem crescente de `CPC` para identificar campanhas mais eficazes.\n",
      "\n",
      "Poderá ajustar a análise com base na implementação precisa do \"Success\", pois se o Success for uma coluna categórica ou um valor booleano, pode ser necessário adaptar a maneira como os valores são agregados.\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Escreva uma função em Python para calcular o primeiro insight desta lista de insights: {insights}\n",
    "para um dataset com as seguintes colunas: {colunas}\n",
    "'''\n",
    "\n",
    "system_message = '''\n",
    "    Você é um especialista em Python e pode escrever funções para calcular insights a partir de datasets.\n",
    "'''\n",
    "r = call_llm(GPT_4o, system_message, prompt, None, EASTUS)\n",
    "print(r[\"2.response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campaign_ID</th>\n",
       "      <th>Success</th>\n",
       "      <th>Conversion_Rate</th>\n",
       "      <th>CPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>CAMP-EFQJG0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>734.513274</td>\n",
       "      <td>6.568584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>CAMP-DW2PCN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>592.173913</td>\n",
       "      <td>3.146584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>CAMP-DR08CW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>506.314433</td>\n",
       "      <td>15.612113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>CAMP-XAA2IL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>401.186624</td>\n",
       "      <td>11.143474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>CAMP-TGSIWG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>243.232115</td>\n",
       "      <td>14.130211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>CAMP-MT8VT4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153906</td>\n",
       "      <td>1.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>CAMP-XPNMJQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139972</td>\n",
       "      <td>0.802373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>CAMP-3OCWBF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125975</td>\n",
       "      <td>0.841858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>CAMP-S13C9X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.042792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>CAMP-G2GZR7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>1.043481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Campaign_ID  Success  Conversion_Rate        CPC\n",
       "413  CAMP-EFQJG0      1.0       734.513274   6.568584\n",
       "399  CAMP-DW2PCN      1.0       592.173913   3.146584\n",
       "393  CAMP-DR08CW      1.0       506.314433  15.612113\n",
       "919  CAMP-XAA2IL      1.0       401.186624  11.143474\n",
       "815  CAMP-TGSIWG      1.0       243.232115  14.130211\n",
       "..           ...      ...              ...        ...\n",
       "619  CAMP-MT8VT4      0.0         0.153906   1.010800\n",
       "935  CAMP-XPNMJQ      0.0         0.139972   0.802373\n",
       "108  CAMP-3OCWBF      0.0         0.125975   0.841858\n",
       "778  CAMP-S13C9X      0.0         0.065245   0.042792\n",
       "460  CAMP-G2GZR7      0.0         0.036164   1.043481\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_campaign_performance(df):\n",
    "    \"\"\"\n",
    "    Analisa o desempenho das campanhas com base em sucesso, taxa de conversão e custo por clique.\n",
    "    \n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame Pandas contendo os dados da campanha.\n",
    "        \n",
    "    Retorna:\n",
    "        pd.DataFrame: Um resumo das campanhas com suas métricas de sucesso.\n",
    "    \"\"\"\n",
    "    # Agrupar dados por 'Campaign_ID' e calcular métricas de interesse\n",
    "    campaign_performance = df.groupby('Campaign_ID').agg({\n",
    "        'Success': 'mean',        # Média de sucesso (presumindo que Success é uma métrica numérica)\n",
    "        'Conversion_Rate': 'mean', # Média da taxa de conversão\n",
    "        'CPC': 'mean'              # Média do custo por clique\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Ordenar o dataframe para uma avaliação mais fácil\n",
    "    campaign_performance_sorted = campaign_performance.sort_values(\n",
    "        by=['Success', 'Conversion_Rate', 'CPC'], \n",
    "        ascending=[False, False, True]  # Para maximizar sucesso e taxa de conversão, mas minimizar CPC\n",
    "    )\n",
    "    \n",
    "    return campaign_performance_sorted\n",
    "\n",
    "campaign_performance_sorted = analyze_campaign_performance(df_campaign)\n",
    "campaign_performance_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [{'role': 'system', 'content': 'Aja como um assistente pessoal e ajude-me a organizar minha agenda.'}, {'role': 'user', 'content': 'Com base nessa agenda, qual o próximo horário livre? 12/03/2022 12:00:00 Ocupado 12/03/2022 13:00:00 Ocupado 12/03/2022 14:00:00 Ocupado 12/03/2022 15:00:00 Livre 12/03/2022 16:00:00 Ocupado 12/03/2022 17:00:00 Livre\\n        12/03/2022 18:00:00 Ocupado 12/03/2022 19:00:00 Livre 12/03/2022 20:00:00 Ocupado'}]\n",
      "Elapsed time: 1.8564947999998367\n",
      "Response: O próximo horário livre disponível é às 15:00 do dia 12/03/2022. Gostaria de agendar alguma atividade ou compromisso para esse horário?\n",
      "Num tokens completion: 42\n",
      "Num tokens prompt: 174\n"
     ]
    }
   ],
   "source": [
    "def sample_agenda():\n",
    "    agenda = '''12/03/2022 12:00:00 Ocupado 12/03/2022 13:00:00 Ocupado 12/03/2022 14:00:00 Ocupado 12/03/2022 15:00:00 Livre 12/03/2022 16:00:00 Ocupado 12/03/2022 17:00:00 Livre\n",
    "        12/03/2022 18:00:00 Ocupado 12/03/2022 19:00:00 Livre 12/03/2022 20:00:00 Ocupado'''\n",
    "    question = f\"Com base nessa agenda, qual o próximo horário livre? {agenda}\"\n",
    "    return call_llm(deployment_name=GPT_35_TURBO, \n",
    "                    system_message=\"Aja como um assistente pessoal e ajude-me a organizar minha agenda.\", \n",
    "                    prompt=question, \n",
    "                    file_path=None, \n",
    "                    region=CANADAEAST)\n",
    "\n",
    "resposta = sample_agenda()\n",
    "print_result(resposta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de diferentes tons na resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_system_message_intonation(question):\n",
    "    system_message = {\"despojado\":\"Você é um assitente que sempre responde em tom despojado, de forma didática e em porguguês, apesar de eventualmente citar palavras em inglês.\",\n",
    "                      \"formal\":\"Você é um assistente que sempre responde em tom formal, rebuscado, sem citar palavras em inglês.\",\n",
    "                      \"informal\":\"Você é um assistente que sempre responde em tom informal, de forma didática e em português, com gírias e expressões coloquiais.\"}\n",
    "    \n",
    "\n",
    "    for item in system_message:\n",
    "        print(f\"Resposta com tom {item.upper()}:\")\n",
    "        r = call_llm(GPT_35_TURBO, system_message[item], question, None, \"canadaeast\")\n",
    "        pprint.pprint(r[\"2.response\"])\n",
    "\n",
    "sample_system_message_intonation(\"O que é inteligência artificial?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de diferença entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''Aja como um professor de lógica e explique-me conceitos fundamentais da lógica de \n",
    "maneira estruturada e sucinta com o mínimo de detalhes possível.'''\n",
    "question = \"Conte-me um paradoxo.\"\n",
    "models = [GPT_35_TURBO, GPT_4, GPT_4_32K, GPT_4_TURBO]\n",
    "results = execute_simultaneously(models, system_message, question, True)\n",
    "print_results(system_message, question, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo informações de uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faça uma pergunta ao modelo, seja criativo!\n",
    "system_message = \"Aja com um assitente pessoal e ajude-me a analizar o arquivo anexo.\"\n",
    "file_path = \"../data/img1.jpg\"\n",
    "\n",
    "prompt = ''' \n",
    "\n",
    "do que se trata o arquivo?\n",
    "\n",
    "'''\n",
    "\n",
    "r = call_llm(GPT_4o, system_message, prompt, file_path, EASTUS)[\"2.response\"]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faça uma pergunta ao modelo, seja criativo!\n",
    "system_message = \"Aja com um assitente pessoal e ajude-me a analizar o arquivo anexo.\"\n",
    "\n",
    "file_path = \"../data/emails_tels.jpg\"\n",
    "\n",
    "prompt = ''' \n",
    "\n",
    "extraia os dados da imagem em formato JSON\n",
    "\n",
    "'''\n",
    "\n",
    "r = call_llm(GPT_4o_mini, system_message, prompt, file_path, EASTUS)[\"2.response\"]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "prompt = f'''\n",
    "\n",
    "def sum(a, b):\n",
    "    return a + b\n",
    "\n",
    "sum({a}, {b})\n",
    "\n",
    "'''\n",
    "system_message = \"Aja como um interprete Python e execute o código abaixo.\"\n",
    "file_path = None\n",
    "r = call_llm(GPT_4o, system_message, prompt, file_path, EASTUS)[\"2.response\"]\n",
    "print(r) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
